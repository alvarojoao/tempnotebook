{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "import sys\n",
    "import numpy as np\n",
    "import re, nltk        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def getTrainingData(name):\n",
    "    train_x,train_y = [],[]\n",
    "    txt = open(name)\n",
    "    n_iter = int(txt.readline())\n",
    "    for i in range(n_iter):\n",
    "        line =  txt.readline()\n",
    "        line = line.replace('\\n','')\n",
    "        y_,x_ = line.split(' ',1)\n",
    "        train_x.append(x_)\n",
    "        train_y.append(y_)\n",
    "    return train_x,train_y\n",
    "\n",
    "data_x,data_y = getTrainingData('trainingdata.txt')\n",
    "\n",
    "#Using Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#function to stem text tokens\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "#function to tokenize text elements and removing numbers and punctuation\n",
    "def tokenize(text):\n",
    "    \n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    tokens = text.split(\" \")\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "# Tokenizing and vectorizing the text elements, eleminating stop words, using maximum of 1100 text tokens per document.\n",
    "vectorizer = TfidfVectorizer(analyzer='word',tokenizer=tokenize,lowercase=True,stop_words ='english',max_features =1100)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(data_x)\n",
    "\n",
    "clf = LinearSVC(loss='squared_hinge', penalty=\"l2\", dual=False, tol=1e-3)\n",
    "clf = clf.fit(X_train_tfidf, data_y)\n",
    "\n",
    "#n_test = int(sys.stdin.readline())\n",
    "#for i in range(n_test):\n",
    "#    test_x = sys.stdin.readline()\n",
    "#    X_new_tfidf = vectorizer.transform(test_x)\n",
    "#    predicted = clf.predict(X_new_tfidf)\n",
    "#    print predicted\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5485, 1100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5485"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5485L, 1100L)\n"
     ]
    }
   ],
   "source": [
    "#Convering the document term matrix to numpy nd array\n",
    "corpus_data_features_nd = (X_train_tfidf.toarray())\n",
    "print corpus_data_features_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1'], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n",
    "clf.predict(corpus_data_features_nd[0].reshape(1,-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
